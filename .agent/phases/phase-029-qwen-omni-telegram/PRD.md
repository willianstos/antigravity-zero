# PRD: QWEN OMNI & MULTIMODAL TELEGRAM (Phase 29) ü¶ÖüéôÔ∏èüß†

**Objetivo**: Integrar o modelo local **Qwen2.5-Omni-7B** (servido via vLLM) como o motor cerebral do bot Telegram, habilitando intera√ß√µes multimodais reais (Voz/Texto) e execu√ß√£o de ferramentas via MCP.

## üß± Arquitetura T√©cnica
- **LLM Engine**: vLLM rodando localmente no N√≥ H2 (RTX 3060).
- **Controlador**: `bot/server.js` (Telegraf).
- **Multimodalidade**: 
    - **STT**: Whisper (fallback) ou Qwen-Omni Voice.
    - **TTS**: Google TTS (via `utils/telegram_audio.js`).
- **Orquestra√ß√£o de Ferramentas**: MCP (Model Context Protocol) conectado ao `system-monitor` e `desktop-control`.

## üõ†Ô∏è Roles & Skills
- **@open-code-controller**: Refatora√ß√£o do bot e integra√ß√£o MCP.
- **@administrador-do-sistema**: Gest√£o do lifecycle do vLLM e hardware GPU.
- **@zelador-da-memoria**: Documentar o novo workflow de √°udio.

## //FULL-AUTO TASKS
[ ] **Task 29.1: Motor de Infer√™ncia H2**
    - Executar `bin/qwen-omni-launcher.sh`.
    - Validar disponibilidade do endpoint do vLLM.

[ ] **Task 29.2: Bot Multimodal v2.0**
    - Refatorar `bot/server.js` para usar o Qwen local via OpenAI API client.
    - Implementar pipeline: √Åudio -> Base64 -> STT -> LLM -> TTS -> Telegram.
    - Adicionar bot√µes interativos para ferramentas MCP.

[ ] **Task 29.3: Integra√ß√£o MCP Master**
    - Conectar o bot aos MCP servers locais (`system-monitor`, `github`).
    - Permitir que o bot execute comandos via bot√µes (ex: "Status da GPU", "Git Sync").

[ ] **Task 29.4: Estabilidade & Logs**
    - Garantir que o bot e o vLLM rodem como processos daemon (nohup).
    - Criar monitor de sa√∫de em `artifacts/health.log`.

## üìä Crit√©rios de Aceite
1. Bot responde perguntas usando o Qwen2.5-Omni-7B local.
2. Comandos de voz s√£o transcritos e processados.
3. Bot√µes interativos executam a√ß√µes reais no sistema (MCP).

---
*Jarvis v15.0 - Omni-Motion Protocol*
